<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>qfl的blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">qfl的blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Eagle部署及各项功能" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/17/Eagle%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%90%84%E9%A1%B9%E5%8A%9F%E8%83%BD/" class="article-date">
  <time class="dt-published" datetime="2022-06-17T02:23:39.196Z" itemprop="datePublished">2022-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Eagle部署及各项功能</p>
<p>（1）在&#x2F;export&#x2F;software路径下，上传并解压kafka-eagle-bin-2.1..gz</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/software/</span><br><span class="line">rz</span><br><span class="line">tar -zxvf kafka-eagle-bin-2.1..gz</span><br></pre></td></tr></table></figure>

<p>（2）当解压完kafka-eagle-bin-2.1..gz之后，ls查看，出现kafka-eagle-bin-2.1.0意味着解压成功</p>
<p> （3）进入&#x2F;export&#x2F;software&#x2F;kafka-eagle-bin-2.1.0路径，可发现其中还有一个efak-web-2.1.0.gz解压包，对其解压 </p>
<p>（4）当解压完efak-web-2.1.0.gz之后，ls查看，出现efak-web-2.1.0意味着解压成功</p>
<p> （5）配置eagle </p>
<p> 修改配置文件system-config.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/software/kafka-eagle-bin-2.1.0/efak-web-2.1.0/conf/</span><br><span class="line">vi system-config.properties</span><br></pre></td></tr></table></figure>

<p><img src="/../images/46.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/47.png" alt="在这里插入图片描述"></p>
<p>修改环境变量&#x2F;etc&#x2F;profile，并重新加载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p><img src="/../images/48.png" alt="在这里插入图片描述"></p>
<p>启动前需要手动创建&#x2F;export&#x2F;data&#x2F;db目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /export/data/db</span><br></pre></td></tr></table></figure>

<p>启动Eagle（注意：需要开启zookeeper和kafka）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/software/kafka-eagle-bin-2.1.0/efak-web-2.1.0/bin/</span><br><span class="line">ke.sh start</span><br></pre></td></tr></table></figure>

<p> 进入本地界面，出现下图，Eagle部署完成</p>
<p><img src="/../images/48.jpg" alt="在这里插入图片描述"></p>
<p><img src="/../images/49.jpg" alt="在这里插入图片描述"></p>
<p>Kafka Eagle各项功能</p>
<p>（1）Dashboard</p>
<p> 查看BROKERS、TOPICS、ZOOKEEPERS、Topic LogSize Top10等</p>
<p><img src="/../images/50.jpg" alt="在这里插入图片描述"></p>
<p>BScreen(大屏)</p>
<p> 该模块包含展示消费者和生产者当日及最近7天趋势、Kafka集群读写速度、Kafka集群历史总记录等。</p>
<p>Topics（主题管理）</p>
<p> 该模块包含主题创建、主题管理、主题预览、KSQL查询主题、主题数据写入、主题属性配置等。</p>
<p>Consumers（消费监控）</p>
<p> 该模块包含监控不同消费者组中的Topic被消费的详情，同时，支持查看Lag的历史趋势图</p>
<p>Cluster（集群管理）</p>
<p> 该模块包含Kafka集群和Zookeeper集群的详情展示，例如Kafka的IP和端口、版本号、启动时间、Zookeeper的Leader和Follower。同时，还支持多Kafka集群切换，以及Zookeeper Client数据查看等功能。</p>
<p>Metrics（集群状态）</p>
<p> 该模块包含监控Kafka集群和Zookeeper集群的核心指标，包含Kafka的消息发送趋势、消息大小接收与发送趋势、Zookeeper的连接数趋势等。同时，还支持查看Broker的瞬时指标数据。</p>
<p>System（系统管理）</p>
<p> 该模块包含用户管理，例如创建用户、用户授权、资源管理等</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/17/Eagle%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%90%84%E9%A1%B9%E5%8A%9F%E8%83%BD/" data-id="cl4hun1zp0000fctyf6g94836" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Kafka API使用方法" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/17/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2022-06-17T01:56:27.670Z" itemprop="datePublished">2022-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="titile-Kafka-API使用方法"><a href="#titile-Kafka-API使用方法" class="headerlink" title="titile:Kafka API使用方法"></a>titile:Kafka API使用方法</h2><p> 新建Maven项目，配置pom.xml</p>
<p><img src="/../images/43.png" alt="在这里插入图片描述"></p>
<p> 新建ProducerDemo类，ProducerCallbackDemo类</p>
<p>生产者原理</p>
<p><img src="/../images/44.png" alt="在这里插入图片描述"></p>
<p>（1）Kafka生产者有两个线程，一个为主线程，一个为Sender线程（它是一个守护线程）</p>
<p>（2）消息发送后首先经历拦截器，在拦截器中可以对消息做一些统一的操作，比如：加上统一的标识，然后会被序列化为字节流</p>
<p>（3）到达分区器，分区器主要是对消息去哪个分区做规划</p>
<p>（4）做好分区规划后，消息到达了消息累加器，累加器是一个双端队列（每一个队列对应一个分区），然后将消息封装到ProducerBatch,ProducerBatch也是一个多消息的容器，它是可以不断想里面加入消息的。让消息变成一批次，一批次的。</p>
<p>（5）Sender线程主动从消息累加器中取消息，然后将上一步Deque&lt;partitionId,ProducerBatch&gt;转换为&lt;Node,List&gt;的形式，然后再将其转换为&lt;Node,Request&gt;,这一步是将Kafka消息从逻辑上转换为物理上的主要转折点。从这步开始，就不会关心分区这个逻辑概念，只会注意要发向哪一台机器了</p>
<p>（6）在发送之前，还会将消息转换为Map&lt;Node,Dequen【Requst】&gt;</p>
<p>（7）保存在InFlightRequst中，表示消息发送等待回应</p>
<p>（8）消息发最终由Selector发送</p>
<p> 重要的生产者参数</p>
<p><strong>１.</strong> <em><strong>*acks*</strong></em><br>这个参数主要用来指定分区中必须要有多少个副本都收到这个消息，生产者客户端才认为这条消息成功写入。它涉及消息的可靠性和吞吐量之间的权衡。acks参数有3种类型的值（都是字符串类型）</p>
<p><strong>２.</strong> <em><strong>*max.request.size*</strong></em><br>这个参数用来限制生产者客户端所能发送消息的最大值</p>
<p><strong>３.</strong> <em><strong>*retry.backoff.ms和*</strong></em><br>retries 参数用来配置生产者重试的次数，默认值为0，也就是说在发生异常的时候不进行重试。</p>
<p><strong>４.</strong> <em><strong>*compression.type*</strong></em><br>这个参数用来指定消息的压缩放方式，默认值是“none”,即默认情况下，消息不会被压缩。</p>
<p><strong>５.</strong> <em><strong>*connections.*</strong></em> <a target="_blank" rel="noopener" href="http://max.ides.ms/"><em><strong>*max.ides.ms*</strong></em></a><br>这个参数用来指定在多久之后关闭闲置连接</p>
<p><strong>６.</strong> <a target="_blank" rel="noopener" href="http://6.linger.ms/"><em><strong>*linger.ms*</strong></em></a><br>这个参数用来指定生产者发送 ProducerBatch 之前等待更多的消息（ProducerRecord）加入 ProducerBatch 的时间</p>
<p><strong>７.</strong> <em><strong>*receive.buffer.bytes*</strong></em><br>这个参数用来设置 Socket 接收消息缓冲区（SO_RECBUF）的大小</p>
<p><strong>８.</strong> <em><strong>*send.buffer.bytes*</strong></em><br>这个参数用来设置 Socket 发送消息缓冲区（SO_SNDBUF）的大小</p>
<p><strong>９.</strong> <a target="_blank" rel="noopener" href="http://9.request.timeout.ms/"><em><strong>*request.timeout.ms*</strong></em></a><br>这个参数用来配置 Producer 等待请求响应的最长时间</p>
<p>消费者API</p>
<ol>
<li>一个正常的消费逻辑需要具备以下几个步骤:</li>
</ol>
<p>(1)配置消费者客户端参数</p>
<p>(2)创建相应的消费者实例; </p>
<p>(3)订阅主题; </p>
<p>(4)拉取消息并消费; </p>
<p>(5)提交消费位移 offset;</p>
<p>(6)关闭消费者实例。</p>
<p>  2.正则方式订阅主题</p>
<p>如果消费者采用的是正则表达式的方式(subscribe(Pattern))订阅, 在之后的过程中,如果有人又创建了新的主题,并且主题名字与正表达式相匹配,那么这个消费者就可以消费到新添加的主题中的消息。如果应用程序需要消费多个主题,并且可以处理不同的类型,那么这种订阅方式就很有效。</p>
<p>3.assign 订阅主题</p>
<p>这个方法只接受参数 partitions,用来指定需要订阅的分区</p>
<p>4.subscribe 与 assign 的区别</p>
<p>(1)通过 subscribe()方法订阅主题具有消费者自动再均衡功能 ; </p>
<p>在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。 </p>
<p>当消费组的消费者增加或减少时,分区分配关系会自动调整,以实现消费负载均衡及故障自动转移。</p>
<p>(2)assign() 方法订阅分区时,是不具备消费者自动均衡的功能的; </p>
<p>其实这一点从 assign()方法参数可以看出端倪,两种类型 subscribe()都有 ConsumerRebalanceListener 类型参数的方法,而 assign()方法却没有。</p>
<p>5.消息的消费模式</p>
<p>Kafka 中的消费是基于拉取模式的。消息的消费一般有两种模式:推送模式和拉取模式。</p>
<p>推模式是服务端主动将消息推送给消费者,而拉模式是消费者主动向服务端发起请求来拉取消息</p>
<p>Kafka 中的消息消费是一个不断轮询的过程,消费者所要做的就是重复地调用 poll() 方法, poll() 方法返回的是所订阅的主题(分区)上的一组消息。</p>
<p>6.指定位移消费</p>
<p>seek() 方法:从特定的位移处开始拉取消息</p>
<p>7.再均衡监听器</p>
<p>一个消费组中,一旦有消费者的增减发生,会触发消费者组的 rebalance 再均衡; </p>
<p>如果 A 消费者消费掉的一批消息还没来得及提交 offset, 而它所负责的分区在 rebalance 中转移给了 B 消费者,则有可能发生数据的重复消费处理。此情形下,可以通过再均衡监听器做一定程度的补救;</p>
<p>8.自动位移提交</p>
<p>Kafka 消费的编程逻辑中位移提交是一大难点,自动提交消费位移的方式非常简便,它免去了复杂的位移提交逻辑,让编码更简洁。但随之而来的是重复消费和消息丢失的问题。</p>
<p>(1)重复消费</p>
<p>假设刚刚提交完一次消费位移,然后拉取一批消息进行消费,在下一次自动提交消费位移之前,消费者崩溃了,那么又得从上一次位移提交的地方重新开始消费,这样便发生了重复消费的现象(对于再均衡的情况同样适用)。我们可以通过减小位移提交的时间间隔来减小重复消息的窗口大小,但这样并不能避免重复消费的发送,而且也会使位移提交更加频繁。</p>
<p>(2)丢失消息</p>
<p>拉取线程不断地拉取消息并存入本地缓存, 比如在 BlockingQueue 中, 另一个处理线程从缓存中读取消息并进行相应的逻辑处理</p>
<p>10.新建ConsumerDemo，ConsumerDemo1，ConsumerTask，ConsumerDemo2，ConsumerSeekOffset类</p>
<p>Topic管理API</p>
<p>\1. KafkaAdminClient 不仅可以用来管理 broker、配置和 ACL (Access Control List),还可用来管理主题)提供了以下方法</p>
<p><img src="/../images/45.png" alt="在这里插入图片描述"></p>
<p>1）连接到kafka服务器</p>
<p>2）创建管理对象，使用get方法获取主题名称</p>
<p>3）查看topic具体信息</p>
<p>4）创建topic</p>
<p>5）运行代码</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/17/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" data-id="cl4hun1zu0001fcty05o21v3h" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Kafka命令行操作" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/17/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/" class="article-date">
  <time class="dt-published" datetime="2022-06-17T01:53:08.778Z" itemprop="datePublished">2022-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="title-Kafka命令行操作"><a href="#title-Kafka命令行操作" class="headerlink" title="title:Kafka命令行操作"></a>title:Kafka命令行操作</h2><p>查看当前可用topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/kafka/bin</span><br><span class="line"></span><br><span class="line">kafka-topics.sh --list --zookeeper node1:2181</span><br></pre></td></tr></table></figure>

<p>创建topic</p>
<p>(1)不指定分区创建topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 --create --replication-factor 3 --partitions 3 --topic test</span><br></pre></td></tr></table></figure>

<p>（2）手动指定副本的存储位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1 --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br></pre></td></tr></table></figure>

<p>进入路径下查看分区的分布</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /export/data/kafka-logs</span><br></pre></td></tr></table></figure>

<p>删除 topic（异步线程去删除）删除 topic,需要一个参数处于启用状态: delete.topic.enable &#x3D; true,否则删不掉。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --delete --topic tpc_6 --zookeeper node1：2181</span><br></pre></td></tr></table></figure>

<p>查看topic</p>
<p>（1）列出当前系统中的所有 topic </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 –list</span><br></pre></td></tr></table></figure>

<p>（2）查看 topic 详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1  --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe --topic tpc_1 --zookeper node1:2181 </span><br></pre></td></tr></table></figure>

<p>增加分区数</p>
<p>Kafka 只支持增加分区,不支持减少分区，原因是减少分区,代价太大(数据的转移,日志段拼接合并)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>

<p>动态配置 topic 参数</p>
<p>添加、修改配置参数</p>
<p>（开启压缩发送传输种提高kafka消息吞吐量的有效办法(‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip</span><br></pre></td></tr></table></figure>

<p>（2）删除配置参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type</span><br></pre></td></tr></table></figure>

<p>生产者写入数据、消费者拉取数据</p>
<p>（1）生产者：kafka-console-producer，进入bin路径下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-console-producer.sh --broker-list node1:9092, node2:9092, node3:9092 --topic tpc_1</span><br></pre></td></tr></table></figure>

<p>（2）消费者：kafka-console-producer</p>
<p>#从头开始</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning</span><br></pre></td></tr></table></figure>

<p># 指定要消费的分区,和要消费的起始 offset </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092,node2:9092,node3:9092 --topic tcp_1 --offset 2 --partition 0</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/17/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/" data-id="cl4hun1zw0002fctyafrvdt02" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Kafka环境配置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/12/Kafka%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2022-06-12T08:26:46.680Z" itemprop="datePublished">2022-06-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="title-Kafka环境配置"><a href="#title-Kafka环境配置" class="headerlink" title="title:Kafka环境配置"></a>title:Kafka环境配置</h2><p>上传文件到&#x2F;export&#x2F;server&#x2F;</p>
<p>解压文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.11-2.0.0.tgz</span><br></pre></td></tr></table></figure>

<p>创建软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s kafka_2.11-2.0.0/ kafka</span><br></pre></td></tr></table></figure>

<p>进入&#x2F;export&#x2F;server&#x2F;kafka&#x2F;confifig 修改配置文件server.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/kafka/config</span><br><span class="line"></span><br><span class="line">vim server.properties</span><br></pre></td></tr></table></figure>

<p>21 行内容 broker.id&#x3D;0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">21 broker.id=0</span><br></pre></td></tr></table></figure>

<p>31 行内容 #listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9092 取消注释，内容改为： </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://node1:9092 </span><br></pre></td></tr></table></figure>

<p>PLAINTEXT为通信使用明文（加密ssl） </p>
<p>59 行内容 log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs 为默认日志文件存储位置，改为 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log.dirs=/export/server/data/kafka-logs </span><br></pre></td></tr></table></figure>

<p>63 行内容为 num.partitions&#x3D;1 是默认分区数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">63 num.partitions=1</span><br></pre></td></tr></table></figure>

<p>76 行部分 (数据安全性（持久化之前先放到缓存上，从缓存刷到磁盘上interval.messages interval.ms )</p>
<p>93 行部分（数据保留策略 168&#x2F;24&#x3D;7，1073741824&#x2F;1024&#x3D;1GB，300000ms &#x3D; 300s &#x3D; 5min超过了删掉 </p>
<p>（最后修改时间还是创建时间–&gt;日志段中最晚的一条消息，维护这个最大的时间戳–&gt;用户无法干预）</p>
<p>121 行内容 zookeeper.connect&#x3D;localhost:2181 修改为 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper.connect=node1:2181,node2:2181，node3:2181</span><br></pre></td></tr></table></figure>

<p> 126 行内容 group.initial.rebalance.delay.ms&#x3D;0 修改为 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">group.initial.rebalance.delay.ms=3000 </span><br></pre></td></tr></table></figure>

<p>给 node2和 node3 scp 分发 kafka</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/</span><br><span class="line"></span><br><span class="line">scp -r /export/server/kafka_2.11-2.0.0/ slave1:$pwD</span><br><span class="line"></span><br><span class="line">scp -r /export/server/kafka_2.11-2.0.0/ slave2:$pwD</span><br></pre></td></tr></table></figure>

<p>创建软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /export/server/kafka_2.11-2.0.0/ kafka</span><br></pre></td></tr></table></figure>

<p>配置 kafka 环境变量（注：可以一台一台配，也可以在 node1 完成后发给 node21 和node2）</p>
<p><img src="/../images/42.jpg" alt="在这里插入图片描述"></p>
<p>重新加载环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p>分别在node2 和node3 上修改配置文件 路径：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /exxport/server/kafka/config</span><br></pre></td></tr></table></figure>

<p>将文件 server.properties 的第 21 行的 broker.id&#x3D;0 修改broker.id&#x3D;1 同理 node2 同样操作</p>
<p>将文件 server.properties 的第 31 行listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;node1:9092 修改为 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://node2:9092 </span><br></pre></td></tr></table></figure>

<p>同理node3 同样操作listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;slave1:9092 </p>
<p>启停 kafka (注：kafka 启动需要在 zookeeper 启动的情况下才可) </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /export/server/kafka/config/server.properties </span><br></pre></td></tr></table></figure>

<p>hadoop，zookeeper，kafka启动 </p>
<p>定制脚本一键启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-stop.sh stop</span><br><span class="line"></span><br><span class="line">ssscure kaska start</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/12/Kafka%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" data-id="cl4hun1zx0003fctyg7qk4yhl" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark &amp; Yarn配置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/28/Spark%20&%20Yarn%E9%85%8D%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2022-05-28T13:25:42.101Z" itemprop="datePublished">2022-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="title-Spark-HA-amp-Yarn-配置"><a href="#title-Spark-HA-amp-Yarn-配置" class="headerlink" title="title:Spark HA&amp; Yarn 配置"></a>title:Spark HA&amp; Yarn 配置</h2><p>修改spark-env.sh配置文件,删除<code>SPARK_MASTER_HOST=node1</code>不固定master节点 。将spark-env.sh分发到node2和node3</p>
<p>scp spark-env.sh node2:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;</p>
<p>scp spark-env.sh node3:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;，关闭当前StandAlone集群(之前需开启配置完成的zookeeper)在node1上 启动一个master 和全部worker，cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh</p>
<p><img src="/2022/05/28/Spark%20&%20Yarn%E9%85%8D%E7%BD%AE/Users\柒柒\AppData\Roaming\Typora\typora-user-images\1653744911567.png" alt="1653744911567"></p>
<p>查看状态：node1:8080端口状态为ALIVE，关闭node1的master进程，node2master启用其状态切换为ALIVE</p>
<p>保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中</p>
<p> 链接到YARN中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）</p>
<p><em><strong>*client*</strong></em> <em><strong>*模式测试*</strong></em> </p>
<h6 id><a href="#" class="headerlink" title></a><img src="/../images/37.png" alt="在这里插入图片描述"></h6><p><em><strong>*cluster 模式测试*</strong></em></p>
<p><img src="/../images/38.png" alt="在这里插入图片描述"></p>
<p><em><strong>*通过web UI查看任务运行状态*</strong></em></p>
<p><img src="/../images/39.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/40.png" alt="在这里插入图片描述"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/28/Spark%20&%20Yarn%E9%85%8D%E7%BD%AE/" data-id="cl3pxjjtv0000ycty4ail5faz" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark local&amp; stand-alone配置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/28/Spark%20local&%20stand-alone%E9%85%8D%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2022-05-28T12:19:40.953Z" itemprop="datePublished">2022-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="title-Spark-local-amp-stand-alone配置"><a href="#title-Spark-local-amp-stand-alone配置" class="headerlink" title="title:Spark local&amp; stand-alone配置"></a>title:Spark local&amp; stand-alone配置</h2><p>Anaconda On Linux 安装 (单台服务器脚本安装) </p>
<p>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server；创建虚拟环境 pyspark 基于 python3.8 切换到虚拟环境内</p>
<p><img src="/../images/27.jpg" alt="在这里插入图片描述"></p>
<p>spark 安装 建立软连接 </p>
<p>ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark,添加环境变量</p>
<p>重新加载环境变量文件 cd &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F;进入 pyspark界面</p>
<p><img src="/../images/28.png" alt="在这里插入图片描述"></p>
<p>浏览器访问验证： <a target="_blank" rel="noopener" href="http://master:4040/">http://master:4040/</a></p>
<p><img src="/../images/29.jpg" alt="在这里插入图片描述"></p>
<p>安装上传安装包:Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装（参考 Local模式下 环境变量的配置内容，确保3台都配置.将文件 workers.template 改名为 workers，并配置文件内容将里面的localhost删除.将文件 spark-env.sh.template 改名为 spark-env.sh。在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:</p>
<p><img src="/../images/30.png" alt="在这里插入图片描述"></p>
<p>配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory&#x3D;INFO, console 改为</p>
<p>log4j.rootCategory&#x3D;WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上</p>
<p><img src="/../images/31.png" alt="在这里插入图片描述"></p>
<p>进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin 文件目录下</p>
<p>重新加载环境变量，启动Spark的Master和Worker进程，启动 start-history-server.sh</p>
<p><img src="/../images/32.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/33.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/34.png" alt="在这里插入图片描述"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/28/Spark%20local&%20stand-alone%E9%85%8D%E7%BD%AE/" data-id="cl3pxjju10001ycty1y69c5pk" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-test" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/28/test/" class="article-date">
  <time class="dt-published" datetime="2022-05-28T11:58:33.000Z" itemprop="datePublished">2022-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/05/28/test/">test</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/28/test/" data-id="cl3pu86xp0000p0tyb46qgt2q" data-title="test" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark基础环境配置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/28/Spark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2022-05-28T06:14:48.861Z" itemprop="datePublished">2022-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/05/28/Spark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">Spark基础环境配置</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>JDK配置</p>
<p>上传并解压jdk<br>JDK安装目录重命名为jdk<img src="/../images/1.png" alt="在这里插入图片描述"></p>
<p>配置环境变量 ，重新加载环境变量文件</p>
<p><img src="/../images/2.jpg" alt="在这里插入图片描述"><img src="/../images/3.png" alt="在这里插入图片描述"></p>
<p>分发JDK相关文件到node2、3<br>1.jdk相关文件分发<br>scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_241&#x2F; root@slave1:&#x2F;export&#x2F;servers&#x2F;<br>scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_241&#x2F; root@slave2:&#x2F;export&#x2F;servers&#x2F;<br>2.分发系统环境变量文件至slave1,slave2<br>scp -r &#x2F;etc&#x2F;profile root@slave1:&#x2F;etc&#x2F;profile<br>scp -r &#x2F;etc&#x2F;profile root@slave2:&#x2F;etc&#x2F;profile<br>Hadoop集群的安装和配置<br>上传Hadoop安装包到node1 &#x2F;export&#x2F;server<br>并解压tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz<br>修改配置文件(进入路径 &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop)<br>hadoop-env.sh<br><img src="/../images/4.jpg" alt="在这里插入图片描述"><br>core-site.xml </p>
<p><img src="/../images/5.jpg" alt="在这里插入图片描述"><br>hdfs-site.xml <img src="/../images/6.jpg" alt="在这里插入图片描述"><br>mapred-site.xml<br><img src="/../images/7.jpg" alt="在这里插入图片描述"><br>重新加载环境变量文件</p>
<p><img src="/../images/8.png" alt="在这里插入图片描述">)<br>一键启动</p>
<p><img src="/../images/9.png" alt="在这里插入图片描述">)</p>
<p>输入 jps 查看 </p>
<p><img src="/../images/10.png" alt="在这里插入图片描述"></p>
<p>Web UI页面验证<br>HDFS集群</p>
<p><img src="/../images/11.jpg" alt="在这里插入图片描述"></p>
<p>YARN集群<br><img src="/../images/12.jpg" alt="在这里插入图片描述"><br>Zookeeper的组件安装配置<br>上传并解压zookeeper<br>建立软连接<br><img src="/../images/13.png" alt="在这里插入图片描述"><br><img src="/../images/14.png" alt="在这里插入图片描述"><br>创建一个zkdata文件</p>
<p><img src="/../images/15.png" alt="在这里插入图片描述">)修改配置文件，添加myid配置，创建zkdatas文件存放myid，内容为1</p>
<p><img src="/../images/16.png" alt="在这里插入图片描述">)<br>安装包分发并修改myid的值，建立软连接，node3同理<br><img src="/../images/17.png" alt="在这里插入图片描述"><br>启动zookeeper服务<br><img src="/../images/18.png" alt="在这里插入图片描述"><br><img src="/../images/19.png" alt="在这里插入图片描述"><br><img src="/../images/20.png" alt="在这里插入图片描述"><br>三台主机查看启动状态<br><img src="/../images/21.png" alt="在这里插入图片描述"><br><img src="/../images/22.png" alt="在这里插入图片描述"><br><img src="/../images/23.png" alt="在这里插入图片描述"><br>jps查看进程<br><img src="/../images/24.jpg" alt="在这里插入图片描述"><br><img src="/../images/25.jpg" alt="在这里插入图片描述"><img src="/../images/26.jpg" alt="在这里插入图片描述"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/28/Spark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" data-id="cl3ptjm880000egtya6fbciat" data-title="Spark基础环境配置" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-myfirstblog" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/27/myfirstblog/" class="article-date">
  <time class="dt-published" datetime="2022-05-27T13:54:53.000Z" itemprop="datePublished">2022-05-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/05/27/myfirstblog/">myfirstblog</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/27/myfirstblog/" data-id="cl3ptjm8e0002egty1alqaxep" data-title="myfirstblog" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/27/hello-world/" class="article-date">
  <time class="dt-published" datetime="2022-05-27T13:33:56.931Z" itemprop="datePublished">2022-05-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/05/27/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/27/hello-world/" data-id="cl3ptjm8c0001egtyhrmwcahq" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  

</section>
        <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/06/17/Eagle%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%90%84%E9%A1%B9%E5%8A%9F%E8%83%BD/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/17/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/17/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/12/Kafka%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/05/28/Spark%20&%20Yarn%E9%85%8D%E7%BD%AE/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li></ul>
    </div>
  </div>

  
</aside>
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 By Autoload<br>
      Driven - <a href="https://hexo.io/" target="_blank">Hexo</a>|Theme - <a href="https://github.com/autoload/hexo-theme-auto" target="_blank">Auto</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>